{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"C:\\Spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc=SparkContext(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=sc.textFile(\"C:\\Spark\\README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'# Apache Spark',\n",
       " u'',\n",
       " u'Spark is a fast and general cluster computing system for Big Data. It provides',\n",
       " u'high-level APIs in Scala, Java, Python, and R, and an optimized engine that',\n",
       " u'supports general computation graphs for data analysis. It also supports a',\n",
       " u'rich set of higher-level tools including Spark SQL for SQL and DataFrames,',\n",
       " u'MLlib for machine learning, GraphX for graph processing,',\n",
       " u'and Spark Streaming for stream processing.',\n",
       " u'',\n",
       " u'<http://spark.apache.org/>',\n",
       " u'',\n",
       " u'',\n",
       " u'## Online Documentation',\n",
       " u'',\n",
       " u'You can find the latest Spark documentation, including a programming',\n",
       " u'guide, on the [project web page](http://spark.apache.org/documentation.html).',\n",
       " u'This README file only contains basic setup instructions.',\n",
       " u'',\n",
       " u'## Building Spark',\n",
       " u'',\n",
       " u'Spark is built using [Apache Maven](http://maven.apache.org/).',\n",
       " u'To build Spark and its example programs, run:',\n",
       " u'',\n",
       " u'    build/mvn -DskipTests clean package',\n",
       " u'',\n",
       " u'(You do not need to do this if you downloaded a pre-built package.)',\n",
       " u'',\n",
       " u'You can build Spark using more than one thread by using the -T option with Maven, see [\"Parallel builds in Maven 3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).',\n",
       " u'More detailed documentation is available from the project site, at',\n",
       " u'[\"Building Spark\"](http://spark.apache.org/docs/latest/building-spark.html).',\n",
       " u'',\n",
       " u'For general development tips, including info on developing Spark using an IDE, see [\"Useful Developer Tools\"](http://spark.apache.org/developer-tools.html).',\n",
       " u'',\n",
       " u'## Interactive Scala Shell',\n",
       " u'',\n",
       " u'The easiest way to start using Spark is through the Scala shell:',\n",
       " u'',\n",
       " u'    ./bin/spark-shell',\n",
       " u'',\n",
       " u'Try the following command, which should return 1000:',\n",
       " u'',\n",
       " u'    scala> sc.parallelize(1 to 1000).count()',\n",
       " u'',\n",
       " u'## Interactive Python Shell',\n",
       " u'',\n",
       " u'Alternatively, if you prefer Python, you can use the Python shell:',\n",
       " u'',\n",
       " u'    ./bin/pyspark',\n",
       " u'',\n",
       " u'And run the following command, which should also return 1000:',\n",
       " u'',\n",
       " u'    >>> sc.parallelize(range(1000)).count()',\n",
       " u'',\n",
       " u'## Example Programs',\n",
       " u'',\n",
       " u'Spark also comes with several sample programs in the `examples` directory.',\n",
       " u'To run one of them, use `./bin/run-example <class> [params]`. For example:',\n",
       " u'',\n",
       " u'    ./bin/run-example SparkPi',\n",
       " u'',\n",
       " u'will run the Pi example locally.',\n",
       " u'',\n",
       " u'You can set the MASTER environment variable when running examples to submit',\n",
       " u'examples to a cluster. This can be a mesos:// or spark:// URL,',\n",
       " u'\"yarn\" to run on YARN, and \"local\" to run',\n",
       " u'locally with one thread, or \"local[N]\" to run locally with N threads. You',\n",
       " u'can also use an abbreviated class name if the class is in the `examples`',\n",
       " u'package. For instance:',\n",
       " u'',\n",
       " u'    MASTER=spark://host:7077 ./bin/run-example SparkPi',\n",
       " u'',\n",
       " u'Many of the example programs print usage help if no params are given.',\n",
       " u'',\n",
       " u'## Running Tests',\n",
       " u'',\n",
       " u'Testing first requires [building Spark](#building-spark). Once Spark is built, tests',\n",
       " u'can be run using:',\n",
       " u'',\n",
       " u'    ./dev/run-tests',\n",
       " u'',\n",
       " u'Please see the guidance on how to',\n",
       " u'[run tests for a module, or individual tests](http://spark.apache.org/developer-tools.html#individual-tests).',\n",
       " u'',\n",
       " u'## A Note About Hadoop Versions',\n",
       " u'',\n",
       " u'Spark uses the Hadoop core library to talk to HDFS and other Hadoop-supported',\n",
       " u'storage systems. Because the protocols have changed in different versions of',\n",
       " u'Hadoop, you must build Spark against the same version that your cluster runs.',\n",
       " u'',\n",
       " u'Please refer to the build documentation at',\n",
       " u'[\"Specifying the Hadoop Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)',\n",
       " u'for detailed guidance on building for a particular distribution of Hadoop, including',\n",
       " u'building for particular Hive and Hive Thriftserver distributions.',\n",
       " u'',\n",
       " u'## Configuration',\n",
       " u'',\n",
       " u'Please refer to the [Configuration Guide](http://spark.apache.org/docs/latest/configuration.html)',\n",
       " u'in the online documentation for an overview on how to configure Spark.',\n",
       " u'',\n",
       " u'## Contributing',\n",
       " u'',\n",
       " u'Please review the [Contribution to Spark guide](http://spark.apache.org/contributing.html)',\n",
       " u'for information on how to get started contributing to the project.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'', 71), (u'including', 4), (u'also', 4), (u'to', 17), (u'using', 5)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=data.flatMap(lambda x:x.split(\" \"))\n",
    "w1=word.map(lambda x:(x,1))\n",
    "w2=w1.reduceByKey(lambda x,y:x+y)\n",
    "w3=w2.filter(lambda (x,y):y>3)\n",
    "w3.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(71, u''),\n",
       " (24, u'the'),\n",
       " (17, u'to'),\n",
       " (16, u'Spark'),\n",
       " (12, u'for'),\n",
       " (9, u'and'),\n",
       " (9, u'##'),\n",
       " (8, u'a'),\n",
       " (7, u'run'),\n",
       " (7, u'can'),\n",
       " (7, u'on'),\n",
       " (6, u'is'),\n",
       " (6, u'in'),\n",
       " (5, u'using'),\n",
       " (5, u'of'),\n",
       " (4, u'including'),\n",
       " (4, u'also'),\n",
       " (4, u'Please'),\n",
       " (4, u'with'),\n",
       " (4, u'an'),\n",
       " (4, u'You'),\n",
       " (4, u'build'),\n",
       " (4, u'you'),\n",
       " (4, u'if'),\n",
       " (3, u'Hadoop'),\n",
       " (3, u'For'),\n",
       " (3, u'see'),\n",
       " (3, u'use'),\n",
       " (3, u'or'),\n",
       " (3, u'one'),\n",
       " (3, u'general'),\n",
       " (3, u'example'),\n",
       " (3, u'how'),\n",
       " (3, u'documentation'),\n",
       " (2, u'Shell'),\n",
       " (2, u'cluster'),\n",
       " (2, u'guidance'),\n",
       " (2, u'should'),\n",
       " (2, u'Interactive'),\n",
       " (2, u'do'),\n",
       " (2, u'return'),\n",
       " (2, u'which'),\n",
       " (2, u'SQL'),\n",
       " (2, u'set'),\n",
       " (2, u'Scala'),\n",
       " (2, u'examples'),\n",
       " (2, u'Python,'),\n",
       " (2, u'This'),\n",
       " (2, u'supports'),\n",
       " (2, u'command,'),\n",
       " (2, u'refer'),\n",
       " (2, u'./bin/run-example'),\n",
       " (2, u'Hadoop,'),\n",
       " (2, u'SparkPi'),\n",
       " (2, u'locally'),\n",
       " (2, u'`examples`'),\n",
       " (2, u'It'),\n",
       " (2, u'particular'),\n",
       " (2, u'be'),\n",
       " (2, u'shell:'),\n",
       " (2, u'following'),\n",
       " (2, u'detailed'),\n",
       " (2, u'tests'),\n",
       " (2, u'1000:'),\n",
       " (2, u'To'),\n",
       " (2, u'at'),\n",
       " (2, u'that'),\n",
       " (2, u'Hive'),\n",
       " (2, u'class'),\n",
       " (2, u'building'),\n",
       " (2, u'Python'),\n",
       " (2, u'programs'),\n",
       " (1, u'project.'),\n",
       " (1, u'help'),\n",
       " (1, u'when'),\n",
       " (1, u'MLlib'),\n",
       " (1, u'\"local\"'),\n",
       " (1, u'./dev/run-tests'),\n",
       " (1, u'graph'),\n",
       " (1, u'computation'),\n",
       " (1, u'file'),\n",
       " (1, u'high-level'),\n",
       " (1, u'find'),\n",
       " (1, u'web'),\n",
       " (1, u'using:'),\n",
       " (1, u'Big'),\n",
       " (1, u'run:'),\n",
       " (1, u'Scala,'),\n",
       " (1, u'Running'),\n",
       " (1, u'environment'),\n",
       " (1, u'only'),\n",
       " (1, u'module,'),\n",
       " (1, u'given.'),\n",
       " (1, u'rich'),\n",
       " (1, u'directory.'),\n",
       " (1, u'Apache'),\n",
       " (1, u'sc.parallelize(range(1000)).count()'),\n",
       " (1, u'Building'),\n",
       " (1, u'guide,'),\n",
       " (1, u'than'),\n",
       " (1, u'Programs'),\n",
       " (1, u'Many'),\n",
       " (1, u'Try'),\n",
       " (1, u'built,'),\n",
       " (1, u'YARN,'),\n",
       " (1, u'R,'),\n",
       " (1, u'Example'),\n",
       " (1, u'scala>'),\n",
       " (1, u'Once'),\n",
       " (1, u'-DskipTests'),\n",
       " (1, u'Spark\"](http://spark.apache.org/docs/latest/building-spark.html).'),\n",
       " (1, u'Because'),\n",
       " (1, u'cluster.'),\n",
       " (1, u'name'),\n",
       " (1, u'-T'),\n",
       " (1, u'Testing'),\n",
       " (1, u'Streaming'),\n",
       " (1, u'./bin/pyspark'),\n",
       " (1, u'through'),\n",
       " (1, u'GraphX'),\n",
       " (1, u'them,'),\n",
       " (1, u'guide](http://spark.apache.org/contributing.html)'),\n",
       " (1, u'[run'),\n",
       " (1, u'analysis.'),\n",
       " (1, u'development'),\n",
       " (1, u'abbreviated'),\n",
       " (1, u'thread,'),\n",
       " (1, u'library'),\n",
       " (1, u'individual'),\n",
       " (1, u'MASTER'),\n",
       " (1, u'runs.'),\n",
       " (1, u'[Apache'),\n",
       " (1, u'Pi'),\n",
       " (1, u'instructions.'),\n",
       " (1, u'More'),\n",
       " (1, u'#'),\n",
       " (1, u'processing,'),\n",
       " (1, u'review'),\n",
       " (1, u'its'),\n",
       " (1, u'contributing'),\n",
       " (1, u'Developer'),\n",
       " (1, u'version'),\n",
       " (1, u'provides'),\n",
       " (1, u'print'),\n",
       " (1, u'get'),\n",
       " (1, u'Configuration'),\n",
       " (1, u'[params]`.'),\n",
       " (1, u'available'),\n",
       " (1, u'core'),\n",
       " (1, u'Guide](http://spark.apache.org/docs/latest/configuration.html)'),\n",
       " (1, u'Versions'),\n",
       " (1, u'[\"Parallel'),\n",
       " (1, u'Documentation'),\n",
       " (1, u'several'),\n",
       " (1, u'downloaded'),\n",
       " (1, u'distributions.'),\n",
       " (1, u'Spark.'),\n",
       " (1, u'latest'),\n",
       " (1, u'example:'),\n",
       " (1, u'by'),\n",
       " (1, u'package.'),\n",
       " (1, u'Maven](http://maven.apache.org/).'),\n",
       " (1, u'[\"Building'),\n",
       " (1, u'thread'),\n",
       " (1, u'package'),\n",
       " (1, u'changed'),\n",
       " (1, u'programming'),\n",
       " (1, u'optimized'),\n",
       " (1, u'against'),\n",
       " (1, u'site,'),\n",
       " (1, u'Maven,'),\n",
       " (1,\n",
       "  u'3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).'),\n",
       " (1, u'comes'),\n",
       " (1, u'first'),\n",
       " (1, u'info'),\n",
       " (1, u'contains'),\n",
       " (1, u'overview'),\n",
       " (1, u'package.)'),\n",
       " (1, u'Contributing'),\n",
       " (1, u'(You'),\n",
       " (1, u'Online'),\n",
       " (1, u'tools'),\n",
       " (1, u'your'),\n",
       " (1, u'page](http://spark.apache.org/documentation.html).'),\n",
       " (1, u'threads.'),\n",
       " (1, u'Tests'),\n",
       " (1, u'fast'),\n",
       " (1, u'from'),\n",
       " (1, u'[project'),\n",
       " (1, u'APIs'),\n",
       " (1, u'>>>'),\n",
       " (1, u'system'),\n",
       " (1, u'submit'),\n",
       " (1, u'systems.'),\n",
       " (1, u'start'),\n",
       " (1, u'IDE,'),\n",
       " (1, u'params'),\n",
       " (1, u'build/mvn'),\n",
       " (1, u'way'),\n",
       " (1, u'basic'),\n",
       " (1, u'README'),\n",
       " (1, u'<http://spark.apache.org/>'),\n",
       " (1, u'more'),\n",
       " (1, u'engine'),\n",
       " (1, u'project'),\n",
       " (1, u'option'),\n",
       " (1, u'started'),\n",
       " (1, u'Note'),\n",
       " (1, u'N'),\n",
       " (1, u'usage'),\n",
       " (1, u'versions'),\n",
       " (1, u'DataFrames,'),\n",
       " (1, u'instance:'),\n",
       " (1, u'./bin/spark-shell'),\n",
       " (1, u'easiest'),\n",
       " (1, u'protocols'),\n",
       " (1, u'must'),\n",
       " (1, u'And'),\n",
       " (1, u'builds'),\n",
       " (1, u'developing'),\n",
       " (1, u'this'),\n",
       " (1, u'setup'),\n",
       " (1, u'will'),\n",
       " (1, u'`./bin/run-example'),\n",
       " (1, u'Hadoop-supported'),\n",
       " (1, u'distribution'),\n",
       " (1, u'Maven'),\n",
       " (1, u'are'),\n",
       " (1, u'Data.'),\n",
       " (1, u'mesos://'),\n",
       " (1, u'stream'),\n",
       " (1, u'computing'),\n",
       " (1, u'URL,'),\n",
       " (1, u'higher-level'),\n",
       " (1, u'sample'),\n",
       " (1,\n",
       "  u'tests](http://spark.apache.org/developer-tools.html#individual-tests).'),\n",
       " (1, u'tips,'),\n",
       " (1, u'have'),\n",
       " (1, u'1000).count()'),\n",
       " (1, u'[\"Specifying'),\n",
       " (1, u'[building'),\n",
       " (1, u'configure'),\n",
       " (1, u'information'),\n",
       " (1, u'different'),\n",
       " (1, u'Tools\"](http://spark.apache.org/developer-tools.html).'),\n",
       " (1, u'MASTER=spark://host:7077'),\n",
       " (1, u'no'),\n",
       " (1, u'not'),\n",
       " (1, u'Java,'),\n",
       " (1, u'storage'),\n",
       " (1, u'documentation,'),\n",
       " (1, u'same'),\n",
       " (1, u'machine'),\n",
       " (1, u'need'),\n",
       " (1, u'other'),\n",
       " (1, u'prefer'),\n",
       " (1, u'online'),\n",
       " (1, u'[Contribution'),\n",
       " (1, u'A'),\n",
       " (1, u'About'),\n",
       " (1, u'HDFS'),\n",
       " (1, u'[Configuration'),\n",
       " (1, u'sc.parallelize(1'),\n",
       " (1, u'locally.'),\n",
       " (1, u'[\"Useful'),\n",
       " (1, u'running'),\n",
       " (1, u'uses'),\n",
       " (1,\n",
       "  u'Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)'),\n",
       " (1, u'variable'),\n",
       " (1, u'The'),\n",
       " (1, u'data'),\n",
       " (1, u'built'),\n",
       " (1, u'\"yarn\"'),\n",
       " (1, u'Thriftserver'),\n",
       " (1, u'processing.'),\n",
       " (1, u'pre-built'),\n",
       " (1, u'Alternatively,'),\n",
       " (1, u'programs,'),\n",
       " (1, u'\"local[N]\"'),\n",
       " (1, u'Spark](#building-spark).'),\n",
       " (1, u'clean'),\n",
       " (1, u'<class>'),\n",
       " (1, u'spark://'),\n",
       " (1, u'learning,'),\n",
       " (1, u'requires'),\n",
       " (1, u'talk'),\n",
       " (1, u'graphs')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.map(lambda x:(x[1],x[0])).sortByKey(False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'./dev/run-tests', 1),\n",
       " (u'cluster', 2),\n",
       " (u'also', 4),\n",
       " (u'using:', 1),\n",
       " (u'should', 2),\n",
       " (u'sc.parallelize(range(1000)).count()', 1),\n",
       " (u'Programs', 1),\n",
       " (u'using', 5),\n",
       " (u'scala>', 1),\n",
       " (u'-DskipTests', 1),\n",
       " (u'Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1),\n",
       " (u'Because', 1),\n",
       " (u'cluster.', 1),\n",
       " (u'Testing', 1),\n",
       " (u'./bin/pyspark', 1),\n",
       " (u'guide](http://spark.apache.org/contributing.html)', 1),\n",
       " (u'analysis.', 1),\n",
       " (u'set', 2),\n",
       " (u'see', 3),\n",
       " (u'examples', 2),\n",
       " (u'runs.', 1),\n",
       " (u'instructions.', 1),\n",
       " (u'processing,', 1),\n",
       " (u'its', 1),\n",
       " (u'This', 2),\n",
       " (u'version', 1),\n",
       " (u'provides', 1),\n",
       " (u'supports', 2),\n",
       " (u'[params]`.', 1),\n",
       " (u'Guide](http://spark.apache.org/docs/latest/configuration.html)', 1),\n",
       " (u'Versions', 1),\n",
       " (u'use', 3),\n",
       " (u'several', 1),\n",
       " (u'distributions.', 1),\n",
       " (u'latest', 1),\n",
       " (u'against', 1),\n",
       " (u'site,', 1),\n",
       " (u'3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).',\n",
       "  1),\n",
       " (u'comes', 1),\n",
       " (u'first', 1),\n",
       " (u'contains', 1),\n",
       " (u'Please', 4),\n",
       " (u'tools', 1),\n",
       " (u'page](http://spark.apache.org/documentation.html).', 1),\n",
       " (u'threads.', 1),\n",
       " (u'Tests', 1),\n",
       " (u'fast', 1),\n",
       " (u'APIs', 1),\n",
       " (u'system', 1),\n",
       " (u'submit', 1),\n",
       " (u'`examples`', 2),\n",
       " (u'systems.', 1),\n",
       " (u'start', 1),\n",
       " (u'params', 1),\n",
       " (u'basic', 1),\n",
       " (u'<http://spark.apache.org/>', 1),\n",
       " (u'started', 1),\n",
       " (u'usage', 1),\n",
       " (u'versions', 1),\n",
       " (u'DataFrames,', 1),\n",
       " (u'instance:', 1),\n",
       " (u'./bin/spark-shell', 1),\n",
       " (u'easiest', 1),\n",
       " (u'protocols', 1),\n",
       " (u'must', 1),\n",
       " (u'builds', 1),\n",
       " (u'this', 1),\n",
       " (u'setup', 1),\n",
       " (u'shell:', 2),\n",
       " (u'Hadoop-supported', 1),\n",
       " (u'distribution', 1),\n",
       " (u'mesos://', 1),\n",
       " (u'stream', 1),\n",
       " (u'is', 6),\n",
       " (u'tests', 2),\n",
       " (u'sample', 1),\n",
       " (u'tests](http://spark.apache.org/developer-tools.html#individual-tests).',\n",
       "  1),\n",
       " (u'tips,', 1),\n",
       " (u'Tools\"](http://spark.apache.org/developer-tools.html).', 1),\n",
       " (u'MASTER=spark://host:7077', 1),\n",
       " (u'storage', 1),\n",
       " (u'same', 1),\n",
       " (u'sc.parallelize(1', 1),\n",
       " (u'[\"Useful', 1),\n",
       " (u'uses', 1),\n",
       " (u'Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)',\n",
       "  1),\n",
       " (u'class', 2),\n",
       " (u'Thriftserver', 1),\n",
       " (u'processing.', 1),\n",
       " (u'programs', 2),\n",
       " (u'programs,', 1),\n",
       " (u'Spark](#building-spark).', 1),\n",
       " (u'<class>', 1),\n",
       " (u'spark://', 1),\n",
       " (u'requires', 1),\n",
       " (u'graphs', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.filter(lambda x:'s' in x[0]).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Spark', u'Spark', u'general', u'cluster', u'for']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.filter(lambda x:'r' in x).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'rich', u'run:', u'return', u'run', u'return']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.filter(lambda x:x.startswith('r')).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
